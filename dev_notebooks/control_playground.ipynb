{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c497ef5-9126-48b6-b285-17df0293ed03",
   "metadata": {},
   "source": [
    "# Dev Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8db616d4-a211-4ba0-b506-eabb353815fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.2, Python 3.10.11)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from accelerate import Accelerator, DistributedDataParallelKwargs\n",
    "import gymnasium as gym\n",
    "import minari\n",
    "import torch\n",
    "from gato.training.arguments import TrainingArgs\n",
    "from gato.tasks.text_task import TextTask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56e49d1-e41c-4960-aaa9-d18bfb636ec1",
   "metadata": {},
   "source": [
    "# TextTask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4eda80bd-c095-42f8-9a51-2ebd16cb6cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArgs(\n",
    "    text_datasets=['wikitext-2-v1'], \n",
    "    text_datasets_paths=['wikitext'],\n",
    "    warmup_steps=1,\n",
    "    training_steps=12,\n",
    "    eval_episodes=1,\n",
    "    log_eval_freq=4,\n",
    "    batch_size=4,\n",
    "    text_prop=1.0,\n",
    "    device='cuda',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f99025a-b209-4752-9bae-0511ecbd4f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_task = TextTask(args.text_datasets, args.text_datasets_paths, args.sequence_length, args.tokenizer_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d640680-6c79-419e-a641-101fc5ddc02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gato.policy.gato_policy import GatoPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c103adac-e3a5-4f94-8172-556371dbdb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddp_kwargs = DistributedDataParallelKwargs(find_unused_parameters=True)\n",
    "accelerator = Accelerator(cpu=args.cpu, mixed_precision=args.mixed_precision, split_batches=True, gradient_accumulation_steps=args.gradient_accumulation_steps, kwargs_handlers=[ddp_kwargs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1067c69e-a182-4245-b18b-096c653c8f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GatoPolicy(\n",
    "    device=args.device,\n",
    "    embed_dim=args.embed_dim,\n",
    "    layers=args.layers,\n",
    "    heads=args.heads,\n",
    "    dropout=args.dropout,\n",
    "    mu=args.mu,\n",
    "    M=args.M,\n",
    "    patch_size=args.patch_size,\n",
    "    resid_mid_channels=args.resid_mid_channels,\n",
    "    continuous_tokens=args.continuous_tokens,\n",
    "    discrete_tokens=args.discrete_tokens,\n",
    "    context_len=args.sequence_length,\n",
    "    use_patch_pos_encoding=not args.disable_patch_pos_encoding,\n",
    "    use_pos_encoding=not args.disable_inner_pos_encoding,\n",
    "    activation_fn=args.activation_fn,\n",
    "    pretrained_lm=args.pretrained_lm,\n",
    "    flash=args.flash,\n",
    "    tokenizer_model_name=args.tokenizer_model_name,\n",
    "    pad_seq=args.pad_seq,\n",
    ")\n",
    "model.to(args.device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cb557aa-1123-49f4-8fff-dfc57edf4bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gato.training.schedulers import get_linear_warmup_cosine_decay_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83b24e0b-cb73-4ce9-85b9-32fc6cd5a10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=args.learning_rate,\n",
    "    betas=(args.beta_1, args.beta_2),\n",
    "    eps=args.adam_eps,\n",
    "    weight_decay=args.weight_decay,\n",
    ")\n",
    "\n",
    "# Setup scheduler\n",
    "scheduler = get_linear_warmup_cosine_decay_scheduler(\n",
    "    optimizer, \n",
    "    args.warmup_steps, \n",
    "    args.training_steps, \n",
    "    base_lr=args.learning_rate, \n",
    "    init_lr=args.init_lr, \n",
    "    min_lr=args.learning_rate / args.min_factor, \n",
    "    cosine_decay=not args.disable_cosine_decay,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ca9efd1-bba3-4f43-8b4b-49233a714aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gato.training.trainer import Trainer\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "185af77a-eec5-4cc2-8066-56aedf32b963",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of examples to test : 100 | Actual batch size of test data : 68\n",
      "================================================================================\n",
      "Iteration 0\n",
      "training/learning_rate: 9.285640897740315e-05\n",
      "time/sample_batch: 0.0016694068908691406\n",
      "time/training: 0.9930353164672852\n",
      "evaluation/text/loss: 9.903299871612997\n",
      "evaluation/text/perplexity: 19996.255859375\n",
      "time/total: 20.59604048728943\n",
      "time/evaluation: 19.6029953956604\n",
      "training/train_loss_mean: 10.898804664611816\n",
      "training/train_loss_std: 0.22483853898092993\n",
      "================================================================================\n",
      "Num of examples to test : 100 | Actual batch size of test data : 69\n",
      "================================================================================\n",
      "Iteration 1\n",
      "training/learning_rate: 4.859583227770217e-05\n",
      "time/sample_batch: 0.001455068588256836\n",
      "time/training: 0.3894932270050049\n",
      "evaluation/text/loss: 9.390184202056\n",
      "evaluation/text/perplexity: 11970.306640625\n",
      "time/total: 44.298654556274414\n",
      "time/evaluation: 23.31282091140747\n",
      "training/train_loss_mean: 9.925028562545776\n",
      "training/train_loss_std: 0.20472925814875015\n",
      "================================================================================\n",
      "Num of examples to test : 100 | Actual batch size of test data : 55\n",
      "================================================================================\n",
      "Iteration 2\n",
      "training/learning_rate: 1.1822816187347625e-05\n",
      "time/sample_batch: 0.0033037662506103516\n",
      "time/training: 0.4285907745361328\n",
      "evaluation/text/loss: 9.083531847867098\n",
      "evaluation/text/perplexity: 8809.01953125\n",
      "time/total: 59.21406626701355\n",
      "time/evaluation: 14.486525297164917\n",
      "training/train_loss_mean: 9.370046257972717\n",
      "training/train_loss_std: 0.8302583500931051\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "tasks = [text_task]\n",
    "exp_name = f'{datetime.isoformat(datetime.now())}'\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    optimizer = optimizer,\n",
    "    scheduler = scheduler,\n",
    "    accelerator = accelerator,\n",
    "    tasks = tasks,\n",
    "    exp_name = exp_name,\n",
    "    args=args\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97867478-6359-4566-85b7-11d46cbe0bde",
   "metadata": {},
   "source": [
    "# Pulling apart the training loop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01b6a19-43a3-4eb5-8d90-ba9a679152c7",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e2dae8-b164-4be7-baf1-4b305f504174",
   "metadata": {},
   "source": [
    "# Train iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f8153a-e386-41af-ba6b-15f0412c8fdf",
   "metadata": {},
   "source": [
    "Set the PyTorch model to 'train' mode: https://stackoverflow.com/a/51433411/3937773\n",
    "\n",
    "`model.train()` tells your model that you are training the model.\n",
    "This helps inform layers such as Dropout and BatchNorm, which are designed to behave differently during training and evaluation.\n",
    "For instance, in training mode, BatchNorm updates a moving average on each new batch; whereas, for evaluation mode, these updates are frozen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16c9118e-4324-49df-8972-216fb3bcea13",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93ffed98-ff31-4bf2-862a-df8f537be5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = text_task.sample_batch(args.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c46d19c1-7703-47ad-a425-5e147a16277d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss: 9.800954818725586\n",
      "1 loss: 9.787251472473145\n",
      "2 loss: 9.740415573120117\n",
      "3 loss: 9.643735885620117\n",
      "4 loss: 9.542501449584961\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    logits, loss = model.forward(inputs=inputs, compute_loss=True)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    print(f'{i} loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea1dc45-4e91-4b78-9df3-693f990fff4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
